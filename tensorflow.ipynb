{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes con tensorflow\n",
    "#### Por Francisco Serradilla\n",
    "\n",
    "#### Tareas\n",
    "\n",
    "* [x] Entrenar el perceptrón multicapa suministrado.\n",
    "* [x] Ampliarlo para meter más capas, usar activación relu y evaluar con un conjunto de test.\n",
    "* [x] Entrenar con algunos de los problemas suministrados.\n",
    "* (Opcional) Probar otros optimizadores.\n",
    "* [x] (Opcional) Añadir dropout. ¿Mejora la generalización con alguno de los problemas suministrados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensorflow...\n",
      "Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de grafos\n",
    "\n",
    "print('Loading tensorflow...')\n",
    "import tensorflow as tf\n",
    "print('Loaded')\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "# The value returned by the constructor represents the output of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar un grafo\n",
    "\n",
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "# To run the matmul op we call the session 'run()' method, passing ‘product' which represents the output of the matmul op.  This indicates to the call that we want to get the output of the matmul op back.\n",
    "# All inputs needed by the op are run automatically by the session.  They typically are run in parallel.\n",
    "# The call 'run(product)' thus causes the execution of three ops in the graph: the two constants and matmul. The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# ==> [[ 12.]]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having launched the graph.  \n",
    "init_op = tf.global_variables_initializer() # We first have to add the `init` Op to the graph\n",
    "\n",
    "with tf.Session() as sess: # Launch the graph and run the ops\n",
    "    sess.run(init_op) # Run the 'init' op\n",
    "    print(sess.run(state)) # Print the initial value of 'state'\n",
    "    for _ in range(3): # Run the op that updates 'state' and print 'state'.\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# fetches\n",
    "\n",
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed]) # fetches -> lo que se quiere obtener del cálculo\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga ejemplos\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 10 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 5 #número de capas ocultas de la red\n",
    "datos_cargados = \"circulo\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/circulo.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datos cargados:\n",
      "circulo\n",
      "\n",
      "s1\n",
      "Tensor(\"Sigmoid_4:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W1 = tf.Variable(tf.random_uniform([ni, nh], -0.1, 0.1, dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.random_uniform([nh], -0.1, 0.1, dtype=tf.float32))\n",
    "W2 = tf.Variable(tf.random_uniform([nh, no], -0.1, 0.1, dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.random_uniform([no], -0.1, 0.1, dtype=tf.float32))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s1 = tf.nn.sigmoid(tf.add(tf.matmul(e, W1), b1))\n",
    "s = tf.nn.sigmoid(tf.add(tf.matmul(s1, W2), b2))\n",
    "\n",
    "print(\"\\ndatos cargados:\", datos_cargados,\"\\n\")\n",
    "print(\"s1\")\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el perceptrón multicapa suministrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenamiento para datos circulo \n",
      "\n",
      "Epoch: 100\n",
      "RMS: 0.45542932\n",
      "Accuracy: 0.48\n",
      "Epoch: 200\n",
      "RMS: 0.45535135\n",
      "Accuracy: 0.48\n",
      "Epoch: 300\n",
      "RMS: 0.41734877\n",
      "Accuracy: 0.52\n",
      "Epoch: 400\n",
      "RMS: 0.3361843\n",
      "Accuracy: 0.84\n",
      "Epoch: 500\n",
      "RMS: 0.27995613\n",
      "Accuracy: 0.88\n",
      "Epoch: 600\n",
      "RMS: 0.24006271\n",
      "Accuracy: 0.96\n",
      "Epoch: 700\n",
      "RMS: 0.2096458\n",
      "Accuracy: 1.0\n",
      "Epoch: 800\n",
      "RMS: 0.18800426\n",
      "Accuracy: 1.0\n",
      "Epoch: 900\n",
      "RMS: 0.17148672\n",
      "Accuracy: 1.0\n",
      "Epoch: 1000\n",
      "RMS: 0.15687752\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s)), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.RMSPropOptimizer(0.01).minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s,1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"\\nEntrenamiento para datos\",datos_cargados, \"\\n\")\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar con algunos de los problemas suministrados.\n",
    "Para entrenar con un problema, ejecutar la carga de datos de ese problema y posteriormente ejecutar el entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos morosos \n",
    "\n",
    "ni = 9 # número de entradas\n",
    "nh = 3 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 2 #número de capas ocultas de la red\n",
    "datos_cargados = \"morosos\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/morosos-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/morosos-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar data2 class\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 2 #número de capas ocultas de la red\n",
    "datos_cargados = \"data 3classes nonlinear\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/data_3classes_nonlinear_2D.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "## Para este caso no hay conjunto de test \n",
    "t = np.loadtxt(\"samples/data_3classes_nonlinear_2D.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos quinielas\n",
    "\n",
    "ni = 60 # número de entradas\n",
    "nh = 60 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 25 #número de capas ocultas de la red\n",
    "datos_cargados = \"quinielas\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/quinielas60-3-trn.txt\")\n",
    "inputs = d[:,:ni]\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/quinielas60-3-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos aprobados \n",
    "\n",
    "ni = 3 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 10 #número de capas ocultas de la red\n",
    "datos_cargados = \"aprobado\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/aprobado-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/aprobado-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Ampliar el perceptrón multicapa suministrado para meter más capas, usar activación relu y evaluar con un conjunto de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datos cargados: quinielas \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W = []\n",
    "b = []\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((ni, nh),dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "for _ in range (1,capas-1):\n",
    "    W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, nh), dtype=tf.float32)))\n",
    "    b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, no),  dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([no], dtype=tf.float32)))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s = []\n",
    "s.append(tf.nn.relu(tf.add(tf.matmul(e, W[0]), b[0])))\n",
    "for i in range (capas - 1):\n",
    "    s.append(tf.nn.relu(tf.add(tf.matmul(s[i], W[i+1]), b[i+1])))\n",
    "\n",
    "print(\"\\ndatos cargados:\", datos_cargados,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenamiento para datos quinielas \n",
      "\n",
      "Epoch: 100\n",
      "RMS: 0.4430469\n",
      "RMS test: 0.46161413\n",
      "Accuracy: 0.6040404\n",
      "Accuracy test: 0.53939396\n",
      "Epoch: 200\n",
      "RMS: 0.38536274\n",
      "RMS test: 0.49511075\n",
      "Accuracy: 0.7050505\n",
      "Accuracy test: 0.5090909\n",
      "Epoch: 300\n",
      "RMS: 0.344424\n",
      "RMS test: 0.5247931\n",
      "Accuracy: 0.7164983\n",
      "Accuracy test: 0.47878787\n",
      "Epoch: 400\n",
      "RMS: 0.31864813\n",
      "RMS test: 0.5271068\n",
      "Accuracy: 0.73670036\n",
      "Accuracy test: 0.4848485\n",
      "Epoch: 500\n",
      "RMS: 0.3448087\n",
      "RMS test: 0.55192435\n",
      "Accuracy: 0.7414141\n",
      "Accuracy test: 0.47272727\n",
      "Epoch: 600\n",
      "RMS: 0.29506326\n",
      "RMS test: 0.5415749\n",
      "Accuracy: 0.75151515\n",
      "Accuracy test: 0.4848485\n",
      "Epoch: 700\n",
      "RMS: 0.43831134\n",
      "RMS test: 0.5530704\n",
      "Accuracy: 0.6936027\n",
      "Accuracy test: 0.43636364\n",
      "Epoch: 800\n",
      "RMS: 0.28214943\n",
      "RMS test: 0.54619104\n",
      "Accuracy: 0.75824916\n",
      "Accuracy test: 0.5030303\n",
      "Epoch: 900\n",
      "RMS: 0.2804253\n",
      "RMS test: 0.5438335\n",
      "Accuracy: 0.75959593\n",
      "Accuracy test: 0.4969697\n",
      "Epoch: 1000\n",
      "RMS: 0.256274\n",
      "RMS test: 0.5480623\n",
      "Accuracy: 0.75959593\n",
      "Accuracy test: 0.4909091\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"\\nEntrenamiento para datos\",datos_cargados, \"\\n\")\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print('RMS test:',sess.run(RMS, feed_dict={e: inputsT, d: outputsT}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy test:',sess.run(accuracy, feed_dict={e: inputsT, d: outputsT}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar otros optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizaron los optimizadores:\n",
    "- RMSPropOptimizer\n",
    "- AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Añadir dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de la red DROPOUT\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W = []\n",
    "b = []\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((ni, nh),dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "for _ in range (1,capas-1):\n",
    "    W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, nh), dtype=tf.float32)))\n",
    "    b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, no),  dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([no], dtype=tf.float32)))\n",
    "\n",
    "# aquí definimos la propagación de la red con DROPOUT\n",
    "s = []\n",
    "s.append(tf.nn.relu(tf.add(tf.matmul(e, W[0]), b[0])))\n",
    "\n",
    "y = tf.placeholder(\"float\", [None, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "drop_out = tf.nn.dropout(s[0], keep_prob) \n",
    "\n",
    "s.append(tf.matmul(s[0], W[1]) + b[1]) #DROPOUT primera capa oculta\n",
    "\n",
    "for i in range (1, capas - 1):\n",
    "    s.append(tf.nn.relu(tf.add(tf.matmul(s[i], W[i+1]), b[i+1])))# Entrenamiento CON DROPOUT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\n",
      "RMS: 0.5277136\n",
      "RMS test: 0.5379788\n",
      "Accuracy: 0.26599327\n",
      "Accuracy test: 0.27272728\n",
      "Epoch: 200\n",
      "RMS: 0.4824904\n",
      "RMS test: 0.5680337\n",
      "Accuracy: 0.41144782\n",
      "Accuracy test: 0.33333334\n",
      "Epoch: 300\n",
      "RMS: 0.47418436\n",
      "RMS test: 0.5725417\n",
      "Accuracy: 0.71784514\n",
      "Accuracy test: 0.5030303\n",
      "Epoch: 400\n",
      "RMS: 0.48620343\n",
      "RMS test: 0.57915884\n",
      "Accuracy: 0.7037037\n",
      "Accuracy test: 0.4969697\n",
      "Epoch: 500\n",
      "RMS: 0.47003445\n",
      "RMS test: 0.5789849\n",
      "Accuracy: 0.72390574\n",
      "Accuracy test: 0.4969697\n",
      "Epoch: 600\n",
      "RMS: 0.47001544\n",
      "RMS test: 0.57948685\n",
      "Accuracy: 0.7225589\n",
      "Accuracy test: 0.4969697\n",
      "Epoch: 700\n",
      "RMS: 0.4700007\n",
      "RMS test: 0.5802353\n",
      "Accuracy: 0.72390574\n",
      "Accuracy test: 0.4848485\n",
      "Epoch: 800\n",
      "RMS: 0.46996245\n",
      "RMS test: 0.58101946\n",
      "Accuracy: 0.72390574\n",
      "Accuracy test: 0.47878787\n",
      "Epoch: 900\n",
      "RMS: 0.46980783\n",
      "RMS test: 0.58117914\n",
      "Accuracy: 0.7232323\n",
      "Accuracy test: 0.4848485\n",
      "Epoch: 1000\n",
      "RMS: 0.4695574\n",
      "RMS test: 0.5815864\n",
      "Accuracy: 0.7245791\n",
      "Accuracy test: 0.4848485\n"
     ]
    }
   ],
   "source": [
    "#Entramiento de la red con DROPOUT\n",
    "\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print('RMS test:',sess.run(RMS, feed_dict={e: inputsT, d: outputsT}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy test:',sess.run(accuracy, feed_dict={e: inputsT, d: outputsT}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación DROPOUT (datos quinielas)\n",
    "\n",
    "Se cargan los datos de quinielas, es el mas complejo de los que hemos decidido cargar en esta práctica, y al realizar el entrenamiento con dropout y sin dropout hemos podido observar que con dropout se generaliza un poco mas la red y, por lo tanto, en la precisión (accuracy) de los datos en test es algo mejor que en el entramiento.\n",
    "Sin dropout el entramiento nos ha llegado a salir una precisión muy buena (en torno al 0.9) y, sin embargo, en el test dan resultados bastante malos. Con el dropout no conseguimos tanta precisión (lo máximo alrededor 0.85), pero en el test si conseguimos mejores resultados debidos a dicha generalización.\n",
    "\n",
    "Esto se dará en los demás ejemplos pero este es mas visible pues no hemos llegado a lograr el 1.0 de precisión.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
