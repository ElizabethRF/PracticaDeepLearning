{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes con tensorflow\n",
    "#### Por Francisco Serradilla\n",
    "\n",
    "#### Tareas\n",
    "\n",
    "* [x] Entrenar el perceptrón multicapa suministrado.\n",
    "* [x] Ampliarlo para meter más capas, usar activación relu y evaluar con un conjunto de test.\n",
    "* Entrenar con algunos de los problemas suministrados.\n",
    "* (Opcional) Probar otros optimizadores.\n",
    "* (Opcional) Añadir dropout. ¿Mejora la generalización con alguno de los problemas suministrados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensorflow...\n",
      "Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de grafos\n",
    "\n",
    "print('Loading tensorflow...')\n",
    "import tensorflow as tf\n",
    "print('Loaded')\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "# The value returned by the constructor represents the output of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar un grafo\n",
    "\n",
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "# To run the matmul op we call the session 'run()' method, passing ‘product' which represents the output of the matmul op.  This indicates to the call that we want to get the output of the matmul op back.\n",
    "# All inputs needed by the op are run automatically by the session.  They typically are run in parallel.\n",
    "# The call 'run(product)' thus causes the execution of three ops in the graph: the two constants and matmul. The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# ==> [[ 12.]]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having launched the graph.  \n",
    "init_op = tf.global_variables_initializer() # We first have to add the `init` Op to the graph\n",
    "\n",
    "with tf.Session() as sess: # Launch the graph and run the ops\n",
    "  sess.run(init_op) # Run the 'init' op\n",
    "  print(sess.run(state)) # Print the initial value of 'state'\n",
    "  for _ in range(3): # Run the op that updates 'state' and print 'state'.\n",
    "    sess.run(update)\n",
    "    print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# fetches\n",
    "\n",
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed]) # fetches -> lo que se quiere obtener del cálculo\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run(output, feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga ejemplos\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 15 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 5 #número de capas ocultas de la red\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/circulo.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1\n",
      "Tensor(\"Sigmoid_2:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W1 = tf.Variable(tf.random_uniform([ni, nh], -0.1, 0.1, dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.random_uniform([nh], -0.1, 0.1, dtype=tf.float32))\n",
    "W2 = tf.Variable(tf.random_uniform([nh, no], -0.1, 0.1, dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.random_uniform([no], -0.1, 0.1, dtype=tf.float32))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s1 = tf.nn.sigmoid(tf.add(tf.matmul(e, W1), b1))\n",
    "s = tf.nn.sigmoid(tf.add(tf.matmul(s1, W2), b2))\n",
    "\n",
    "print(\"s1\")\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "Tensor(\"Placeholder_25:0\", shape=(?, 3), dtype=float32)\n",
      "s\n",
      "Tensor(\"Sigmoid_1:0\", shape=(?, 3), dtype=float32)\n",
      "Epoch: 100\n",
      "RMS: 0.45564017\n",
      "Accuracy: 0.48\n",
      "Epoch: 200\n",
      "RMS: 0.455374\n",
      "Accuracy: 0.48\n",
      "Epoch: 300\n",
      "RMS: 0.42243877\n",
      "Accuracy: 0.48\n",
      "Epoch: 400\n",
      "RMS: 0.3547264\n",
      "Accuracy: 0.76\n",
      "Epoch: 500\n",
      "RMS: 0.3022972\n",
      "Accuracy: 0.84\n",
      "Epoch: 600\n",
      "RMS: 0.26390263\n",
      "Accuracy: 0.92\n",
      "Epoch: 700\n",
      "RMS: 0.23606855\n",
      "Accuracy: 1.0\n",
      "Epoch: 800\n",
      "RMS: 0.21393009\n",
      "Accuracy: 1.0\n",
      "Epoch: 900\n",
      "RMS: 0.19558491\n",
      "Accuracy: 1.0\n",
      "Epoch: 1000\n",
      "RMS: 0.18010312\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "print(\"d\")\n",
    "print(d)\n",
    "print(\"s\")\n",
    "print(s)\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s)), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.RMSPropOptimizer(0.01).minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s,1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos morosos \n",
    "\n",
    "ni = 9 # número de entradas\n",
    "nh = 3 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 2 #número de capas ocultas de la red\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/morosos-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar data2 class\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 5 #número de capas ocultas de la red\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/data_3classes_nonlinear_2D.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos quinielas\n",
    "\n",
    "ni = 60 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 4 #número de capas ocultas de la red\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/quinielas60-3-trn.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos aprobados \n",
    "\n",
    "ni = 3 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 10 #número de capas ocultas de la red\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/aprobado-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "[<tf.Tensor 'Relu_95:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'Relu_96:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'Relu_97:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'Relu_98:0' shape=(?, 15) dtype=float32>, <tf.Tensor 'Relu_99:0' shape=(?, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W = []\n",
    "b = []\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((ni, nh),dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "for _ in range (1,capas-1):\n",
    "    W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, nh), dtype=tf.float32)))\n",
    "    b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, no),  dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([no], dtype=tf.float32)))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s = []\n",
    "s.append(tf.nn.relu(tf.add(tf.matmul(e, W[0]), b[0])))\n",
    "for i in range (capas - 1):\n",
    "    s.append(tf.nn.relu(tf.add(tf.matmul(s[i], W[i+1]), b[i+1])))\n",
    "    \n",
    "print(\"s\")\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\n",
      "RMS: 0.39095473\n",
      "Accuracy: 0.68\n",
      "Epoch: 200\n",
      "RMS: 0.33947322\n",
      "Accuracy: 0.68\n",
      "Epoch: 300\n",
      "RMS: 0.33885527\n",
      "Accuracy: 0.68\n",
      "Epoch: 400\n",
      "RMS: 0.33893725\n",
      "Accuracy: 0.68\n",
      "Epoch: 500\n",
      "RMS: 0.33864462\n",
      "Accuracy: 0.68\n",
      "Epoch: 600\n",
      "RMS: 0.33893752\n",
      "Accuracy: 0.68\n",
      "Epoch: 700\n",
      "RMS: 0.33854952\n",
      "Accuracy: 0.68\n",
      "Epoch: 800\n",
      "RMS: 0.33831987\n",
      "Accuracy: 0.68\n",
      "Epoch: 900\n",
      "RMS: 0.33903947\n",
      "Accuracy: 0.68\n",
      "Epoch: 1000\n",
      "RMS: 0.33879113\n",
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout\n",
      "Tensor(\"dropout_24/mul:0\", shape=(?, 15), dtype=float32)\n",
      "out_layer\n",
      "Tensor(\"add_125:0\", shape=(?, 15), dtype=float32)\n",
      "cost\n",
      "Tensor(\"Mean_173:0\", shape=(), dtype=float32)\n",
      "Epoch: 100\n",
      "RMS: 0.40645924\n",
      "Accuracy: 0.52\n",
      "Epoch: 200\n",
      "RMS: 0.16993956\n",
      "Accuracy: 1.0\n",
      "Epoch: 300\n",
      "RMS: 0.07047657\n",
      "Accuracy: 1.0\n",
      "Epoch: 400\n",
      "RMS: 0.009624799\n",
      "Accuracy: 1.0\n",
      "Epoch: 500\n",
      "RMS: 0.0029722613\n",
      "Accuracy: 1.0\n",
      "Epoch: 600\n",
      "RMS: 0.002685617\n",
      "Accuracy: 1.0\n",
      "Epoch: 700\n",
      "RMS: 0.0022879157\n",
      "Accuracy: 1.0\n",
      "Epoch: 800\n",
      "RMS: 0.0023215988\n",
      "Accuracy: 1.0\n",
      "Epoch: 900\n",
      "RMS: 0.0021818297\n",
      "Accuracy: 1.0\n",
      "Epoch: 1000\n",
      "RMS: 0.0020713555\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Dropout \n",
    "y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)  # DROP-OUT here\n",
    "drop_out = tf.nn.dropout(s[0], keep_prob)  # DROP-OUT here\n",
    "\n",
    "out_layer = tf.matmul(s[0], W[1]) + b[1]\n",
    "# Entrenamiento CON DROPOUT \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_layer,labels= y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "\n",
    "print(\"dropout\")\n",
    "print(drop_out)\n",
    "print(\"out_layer\")\n",
    "print(out_layer)\n",
    "print(\"cost\")\n",
    "print(cost)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
