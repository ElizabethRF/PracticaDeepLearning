{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes con tensorflow\n",
    "#### Por Francisco Serradilla\n",
    "\n",
    "#### Tareas\n",
    "\n",
    "* [x] Entrenar el perceptrón multicapa suministrado.\n",
    "* [x] Ampliarlo para meter más capas, usar activación relu y evaluar con un conjunto de test.\n",
    "* [x] Entrenar con algunos de los problemas suministrados.\n",
    "* (Opcional) Probar otros optimizadores.\n",
    "* [x] (Opcional) Añadir dropout. ¿Mejora la generalización con alguno de los problemas suministrados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensorflow...\n",
      "Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul_1:0' shape=(1, 1) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de grafos\n",
    "\n",
    "print('Loading tensorflow...')\n",
    "import tensorflow as tf\n",
    "print('Loaded')\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "# The value returned by the constructor represents the output of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar un grafo\n",
    "\n",
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "# To run the matmul op we call the session 'run()' method, passing ‘product' which represents the output of the matmul op.  This indicates to the call that we want to get the output of the matmul op back.\n",
    "# All inputs needed by the op are run automatically by the session.  They typically are run in parallel.\n",
    "# The call 'run(product)' thus causes the execution of three ops in the graph: the two constants and matmul. The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# ==> [[ 12.]]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alba\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "\n",
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having launched the graph.  \n",
    "init_op = tf.global_variables_initializer() # We first have to add the `init` Op to the graph\n",
    "\n",
    "with tf.Session() as sess: # Launch the graph and run the ops\n",
    "    sess.run(init_op) # Run the 'init' op\n",
    "    print(sess.run(state)) # Print the initial value of 'state'\n",
    "    for _ in range(3): # Run the op that updates 'state' and print 'state'.\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "# fetches\n",
    "\n",
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed]) # fetches -> lo que se quiere obtener del cálculo\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga ejemplos\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 10 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 5 #número de capas ocultas de la red\n",
    "datos_cargados = \"circulo\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/circulo.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datos cargados: circulo \n",
      "\n",
      "s1\n",
      "Tensor(\"Sigmoid:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W1 = tf.Variable(tf.random_uniform([ni, nh], -0.1, 0.1, dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.random_uniform([nh], -0.1, 0.1, dtype=tf.float32))\n",
    "W2 = tf.Variable(tf.random_uniform([nh, no], -0.1, 0.1, dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.random_uniform([no], -0.1, 0.1, dtype=tf.float32))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s1 = tf.nn.sigmoid(tf.add(tf.matmul(e, W1), b1))\n",
    "s = tf.nn.sigmoid(tf.add(tf.matmul(s1, W2), b2))\n",
    "\n",
    "print(\"\\ndatos cargados:\", datos_cargados,\"\\n\")\n",
    "print(\"s1\")\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el perceptrón multicapa suministrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alba\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Entrenamiento para datos circulo \n",
      "\n",
      "Epoch: 100\n",
      "RMS: 0.4554516\n",
      "Accuracy: 0.48\n",
      "Epoch: 200\n",
      "RMS: 0.45537496\n",
      "Accuracy: 0.48\n",
      "Epoch: 300\n",
      "RMS: 0.42150363\n",
      "Accuracy: 0.56\n",
      "Epoch: 400\n",
      "RMS: 0.34897864\n",
      "Accuracy: 0.84\n",
      "Epoch: 500\n",
      "RMS: 0.2962158\n",
      "Accuracy: 0.84\n",
      "Epoch: 600\n",
      "RMS: 0.25511953\n",
      "Accuracy: 0.96\n",
      "Epoch: 700\n",
      "RMS: 0.22278762\n",
      "Accuracy: 1.0\n",
      "Epoch: 800\n",
      "RMS: 0.19427179\n",
      "Accuracy: 1.0\n",
      "Epoch: 900\n",
      "RMS: 0.16483466\n",
      "Accuracy: 1.0\n",
      "Epoch: 1000\n",
      "RMS: 0.13522689\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s)), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.RMSPropOptimizer(0.01).minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s,1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"\\nEntrenamiento para datos\",datos_cargados, \"\\n\")\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar con algunos de los problemas suministrados.\n",
    "Para entrenar con un problema, ejecutar la carga de datos de ese problema y posteriormente ejecutar el entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos morosos \n",
    "\n",
    "ni = 9 # número de entradas\n",
    "nh = 3 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 2 #número de capas ocultas de la red\n",
    "datos_cargados = \"morosos\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/morosos-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/morosos-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar data2 class\n",
    "\n",
    "ni = 2 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 2 #número de capas ocultas de la red\n",
    "datos_cargados = \"data 3classes nonlinear\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/data_3classes_nonlinear_2D.txt\")\n",
    "inputs = d[:,:ni]\n",
    "\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "## Para este caso no hay conjunto de test \n",
    "t = np.loadtxt(\"samples/data_3classes_nonlinear_2D.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos quinielas\n",
    "\n",
    "ni = 60 # número de entradas\n",
    "nh = 60 # número de neuronas en capa oculta\n",
    "no = 3 # número de neuronas en capa de salida\n",
    "capas = 25 #número de capas ocultas de la red\n",
    "datos_cargados = \"quinielas\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/quinielas60-3-trn.txt\")\n",
    "inputs = d[:,:ni]\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/quinielas60-3-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos aprobados \n",
    "\n",
    "ni = 3 # número de entradas\n",
    "nh = 7 # número de neuronas en capa oculta\n",
    "no = 1 # número de neuronas en capa de salida\n",
    "capas = 10 #número de capas ocultas de la red\n",
    "datos_cargados = \"aprobado\"\n",
    "\n",
    "# carga datos de entrenamiento\n",
    "d = np.loadtxt(\"samples/aprobado-ent.txt\")\n",
    "inputs = d[:,:ni]\n",
    "outputs = d[:,ni:]\n",
    "\n",
    "t = np.loadtxt(\"samples/aprobado-tst.txt\")\n",
    "inputsT = t[:,:ni]\n",
    "outputsT = t[:,ni:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Ampliar el perceptrón multicapa suministrado para meter más capas, usar activación relu y evaluar con un conjunto de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "datos cargados: quinielas \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creación de la red\n",
    "# Define un perceptrón multicapa con 2 capas usando RMS como medida del error y back proagation como algoritmo de entrenamiento\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W = []\n",
    "b = []\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((ni, nh),dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "for _ in range (1,capas-1):\n",
    "    W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, nh), dtype=tf.float32)))\n",
    "    b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, no),  dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([no], dtype=tf.float32)))\n",
    "\n",
    "# aquí definimos la propagación de la red\n",
    "s = []\n",
    "s.append(tf.nn.relu(tf.add(tf.matmul(e, W[0]), b[0])))\n",
    "for i in range (capas - 1):\n",
    "    s.append(tf.nn.relu(tf.add(tf.matmul(s[i], W[i+1]), b[i+1])))\n",
    "\n",
    "print(\"\\ndatos cargados:\", datos_cargados,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenamiento para datos quinielas \n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "RMS: 0.42289054\n",
      "RMS test: 0.43324438\n",
      "Accuracy: 0.58518517\n",
      "Accuracy test: 0.5272727\n",
      "\n",
      "Epoch: 200\n",
      "RMS: 0.34734538\n",
      "RMS test: 0.5013001\n",
      "Accuracy: 0.7225589\n",
      "Accuracy test: 0.4121212\n",
      "\n",
      "Epoch: 300\n",
      "RMS: 0.26921713\n",
      "RMS test: 0.5202158\n",
      "Accuracy: 0.86599326\n",
      "Accuracy test: 0.4121212\n",
      "\n",
      "Epoch: 400\n",
      "RMS: 0.17903815\n",
      "RMS test: 0.57969797\n",
      "Accuracy: 0.93468016\n",
      "Accuracy test: 0.4181818\n",
      "\n",
      "Epoch: 500\n",
      "RMS: 0.25668693\n",
      "RMS test: 0.5694006\n",
      "Accuracy: 0.8922559\n",
      "Accuracy test: 0.38787878\n",
      "\n",
      "Epoch: 600\n",
      "RMS: 0.10844108\n",
      "RMS test: 0.57723135\n",
      "Accuracy: 0.9878788\n",
      "Accuracy test: 0.42424244\n",
      "\n",
      "Epoch: 700\n",
      "RMS: 0.14564045\n",
      "RMS test: 0.57716125\n",
      "Accuracy: 0.95555556\n",
      "Accuracy test: 0.44242424\n",
      "\n",
      "Epoch: 800\n",
      "RMS: 0.11154207\n",
      "RMS test: 0.5837092\n",
      "Accuracy: 0.96498317\n",
      "Accuracy test: 0.45454547\n",
      "\n",
      "Epoch: 900\n",
      "RMS: 0.11098633\n",
      "RMS test: 0.5880737\n",
      "Accuracy: 0.96498317\n",
      "Accuracy test: 0.44848484\n",
      "\n",
      "Epoch: 1000\n",
      "RMS: 0.118270814\n",
      "RMS test: 0.58203673\n",
      "Accuracy: 0.96363634\n",
      "Accuracy test: 0.44242424\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "\n",
    "# definimos la función a minimizar (error cuadrático medio)\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"\\nEntrenamiento para datos\",datos_cargados, \"\\n\")\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('\\nEpoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print('RMS test:',sess.run(RMS, feed_dict={e: inputsT, d: outputsT}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy test:',sess.run(accuracy, feed_dict={e: inputsT, d: outputsT}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar otros optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizaron los optimizadores:\n",
    "- **RMSPropOptimizer**\n",
    "RMSprop es un optimizado rápido y popular diseñado para redes de neuronas que utiliza métodos de cambio de tasa para el aprendizaje adaptativo. Este algoritmo trata de resolver el problema de que los gradientes pueden variar ampliamente. Hace una generalización que garantiza que todas las actualizaciones de los pesos sean del mismo tamaño. \n",
    "\n",
    "- **AdamOptimizer**\n",
    "El algoritmo de optimización de Adam es una extensión del descenso de gradiente que se utiliza para deep Learning y normalmente para visión por computadora y procesamiento de lenguaje natural. Lo que hace es actualizar los pesos iterativamente basándose en los datos entrenados, a diferencia del algoritmo tradicional que mantiene una tasa de aprendizaje a lo largo de todo el entrenamiento. \n",
    "Adam ayuda a obtener buenos resultados de forma rápida y se recomienda que sea el algoritmo por defecto. \n",
    "\n",
    "\n",
    "Referencias: \n",
    "- Brownlee, J. (2017). Gentle Introduction to the Adam Optimization Algorithm for Deep Learning. Machine Learning Mastery. Retrieved 1 May 2019, from https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "- Understanding RMSprop — faster neural network learning. (2018). Towards Data Science. Retrieved 1 May 2019, from https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Añadir dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de la red DROPOUT\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# un placeholder es un punto de comunicación de datos entre nuestra app y la librería tensorflow\n",
    "# creamos un placeholder para indicar las entradas a la red de todos los ejemplos\n",
    "e = tf.placeholder(tf.float32, [None, ni]) # None indica que la primera dimensión no es fija (el número de ejemplos)\n",
    "\n",
    "# un nuevo placeholder para indicar las salidas deseadas\n",
    "d = tf.placeholder(tf.float32, [None, no])\n",
    "\n",
    "# las variables son matrices que residen fuera de python y no son modificadas directamente por nuestra app\n",
    "W = []\n",
    "b = []\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((ni, nh),dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "for _ in range (1,capas-1):\n",
    "    W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, nh), dtype=tf.float32)))\n",
    "    b.append(tf.Variable(tf.glorot_uniform_initializer()([nh], dtype=tf.float32)))\n",
    "\n",
    "W.append(tf.Variable(tf.glorot_uniform_initializer()((nh, no),  dtype=tf.float32)))\n",
    "b.append(tf.Variable(tf.glorot_uniform_initializer()([no], dtype=tf.float32)))\n",
    "\n",
    "# aquí definimos la propagación de la red con DROPOUT\n",
    "s = []\n",
    "s.append(tf.nn.relu(tf.add(tf.matmul(e, W[0]), b[0])))\n",
    "\n",
    "y = tf.placeholder(\"float\", [None, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "drop_out = tf.nn.dropout(s[0], keep_prob) \n",
    "\n",
    "s.append(tf.matmul(s[0], W[1]) + b[1]) #DROPOUT primera capa oculta\n",
    "\n",
    "for i in range (1, capas - 1):\n",
    "    s.append(tf.nn.relu(tf.add(tf.matmul(s[i], W[i+1]), b[i+1])))# Entrenamiento CON DROPOUT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\n",
      "RMS: 0.5027157\n",
      "RMS test: 0.5170534\n",
      "Accuracy: 0.34074074\n",
      "Accuracy test: 0.28484848\n",
      "Epoch: 200\n",
      "RMS: 0.4668431\n",
      "RMS test: 0.5336231\n",
      "Accuracy: 0.41144782\n",
      "Accuracy test: 0.29090908\n",
      "Epoch: 300\n",
      "RMS: 0.4692955\n",
      "RMS test: 0.5534565\n",
      "Accuracy: 0.42087543\n",
      "Accuracy test: 0.2969697\n",
      "Epoch: 400\n",
      "RMS: 0.42442146\n",
      "RMS test: 0.5557351\n",
      "Accuracy: 0.68686867\n",
      "Accuracy test: 0.44242424\n",
      "Epoch: 500\n",
      "RMS: 0.35204205\n",
      "RMS test: 0.5870443\n",
      "Accuracy: 0.84175086\n",
      "Accuracy test: 0.44848484\n",
      "Epoch: 600\n",
      "RMS: 0.32112747\n",
      "RMS test: 0.60179\n",
      "Accuracy: 0.96430975\n",
      "Accuracy test: 0.46060607\n",
      "Epoch: 700\n",
      "RMS: 0.31893826\n",
      "RMS test: 0.6018736\n",
      "Accuracy: 0.9683502\n",
      "Accuracy test: 0.45454547\n",
      "Epoch: 800\n",
      "RMS: 0.31891736\n",
      "RMS test: 0.59941095\n",
      "Accuracy: 0.96700335\n",
      "Accuracy test: 0.45454547\n",
      "Epoch: 900\n",
      "RMS: 0.3181843\n",
      "RMS test: 0.5931241\n",
      "Accuracy: 0.9690236\n",
      "Accuracy test: 0.47272727\n",
      "Epoch: 1000\n",
      "RMS: 0.31816477\n",
      "RMS test: 0.590388\n",
      "Accuracy: 0.9690236\n",
      "Accuracy test: 0.4909091\n"
     ]
    }
   ],
   "source": [
    "#Entramiento de la red con DROPOUT\n",
    "\n",
    "vRMS = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(d,s[capas-1])), reduction_indices=0))\n",
    "RMS = tf.reduce_mean(vRMS)\n",
    "\n",
    "# definimos el algoritmo de aprendizaje a utilizar (descenso del gradiente sobre la función de coste)\n",
    "train_step = tf.train.AdamOptimizer().minimize(RMS)\n",
    "\n",
    "# definimos qué es un acierto  \n",
    "correct_prediction = tf.equal(tf.argmax(s[capas-1],1), tf.argmax(d,1))\n",
    "\n",
    "# definimos la precisión como el porcentaje de aciertos\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# definimos la inicialización de las variables internas\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# iniciamos sesión con tensorflow y ejecutamos la inicialización\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# ejecutamos el número de epochs indicados\n",
    "epochs = 1000\n",
    "trace = 100\n",
    "for i in range(1,epochs+1):\n",
    "  sess.run(train_step, feed_dict={e: inputs, d: outputs})\n",
    "  if i%trace == 0:\n",
    "    print ('Epoch: %d' % i)\n",
    "    # calculamos RMS y precisión y la escribimos por pantalla\n",
    "    print('RMS:',sess.run(RMS, feed_dict={e: inputs, d: outputs}))\n",
    "    print('RMS test:',sess.run(RMS, feed_dict={e: inputsT, d: outputsT}))\n",
    "    print ('Accuracy:',sess.run(accuracy, feed_dict={e: inputs, d: outputs}))\n",
    "    print ('Accuracy test:',sess.run(accuracy, feed_dict={e: inputsT, d: outputsT}))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación DROPOUT (datos quinielas)\n",
    "\n",
    "El ejemplo mas complejo que hemos cargado en esta prática es el de \"quinielas\" y por ello vamos a razonar el dropout con estos datos para que sea mas visual.En el resto de ejemplos también se produciría.\n",
    "Al realizar el entrenamiento con dropout y sin dropout (mostrados arriba) se puede observar que con dropout se generaliza un poco mas la red y, por lo tanto, en la precisión (accuracy) de los resultados en test son algo mejores en la ejecución con dropout.\n",
    "\n",
    "Ejemplo quinielas:\n",
    "\n",
    "Sin dropout el entramiento nos ha llegado a salir una precisión muy buena (en torno al 0.95) y, sin embargo, en el test dan resultados bastante malos, aproximidamente 0.44. Si se introduce dropout, en el entramiento podemos alcanzar una probabilidad similar, pero en el test si se consiguen resultados mejores (0.5 aprox.).\n",
    "\n",
    "Por ello, como respuesta a la pregunta del enunciado, se puede decir que si es posible mejorar la generalización con dropout.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
